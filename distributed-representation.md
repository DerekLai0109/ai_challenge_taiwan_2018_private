# Distributed Representation

![](/assets/joint_probability_vs_distributed_representation_0303.jpg)Learning joint probability v.s. distributed representation

Fig. shows the mechanism improvement from learning joint probability to distributed representation. 

Statistical NLP has emerged as the primary option for modeling natural language tasks.However, it often used to suffer from the "curse of dimensionality" while learning joint probability functions of language models. This led to the motivation of learning distributed representations of words existing in low-dimensional space.The concept of distributed representation is the basis of deep learning model.



