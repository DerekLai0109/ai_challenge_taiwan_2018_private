## Linear SVC Machine learning SVM example with Pyhon

180302 CCL

### A simple example about working with Linear SVC

The objective of a Linear SVC \(support Vector Classifier\) is ~~_**to fit to**_~~ the data you provided, returning a "best fit" hyperplane that categorizes your data. After getting the hyperplane, you can feed some features to your classifier to see what the "predicted" class is.

**Import packages**![](/assets/SVM_CODE_01.png)Maitipzlotlib is for data visualization that can show how linear SVC works. And Numpy is for array conversion.

**Define features**

These features  will be visualized  as axis on the graph.![](/assets/SVM_CODE_02.png)Graph the data.![](/assets/SVM_CODE_03.png)Result 01 \(ADD FIG\)

**FIG!!  **

**Compile an array**

Two groups can be divided without further calculation. But, to draw the exact dividing line need further calculation.

To feed data into the machine learning algorithm, compiling an array of the features is required, rather than having them as x and y coordinate values. 

The features \(x and y\) is stored in X variable.![](/assets/SVM_CODE_04.png)



Two features de rive a 2D graph. Thus, th problem occurs when there are thousands more features.



**\*\* 再把CODE&RESULTS貼上來!**

**Environment: Anoconda**

**REF**

[https://pythonprogramming.net/linear-svc-example-scikit-learn-svm-python/](https://pythonprogramming.net/linear-svc-example-scikit-learn-svm-python/)

